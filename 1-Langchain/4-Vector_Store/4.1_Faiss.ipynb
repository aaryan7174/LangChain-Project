{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7f1e1e",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "432edc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk 1: 'My parents impressed on me the'\n",
      "\n",
      "Chunk 2: 'on me the value of that you'\n",
      "\n",
      "Chunk 3: 'that you work hard for what'\n",
      "\n",
      "Chunk 4: 'for what you want in life'\n",
      "\n",
      "Chunk 5: '.'\n",
      "\n",
      "Chunk 6: 'That your word is your bond'\n",
      "\n",
      "Chunk 7: 'your bond and you do what you'\n",
      "\n",
      "Chunk 8: 'what you say and keep your'\n",
      "\n",
      "Chunk 9: 'keep your promise'\n",
      "\n",
      "Chunk 10: '.'\n",
      "\n",
      "Chunk 11: 'That you treat people with'\n",
      "\n",
      "Chunk 12: 'with respect'\n",
      "\n",
      "Chunk 13: '.'\n",
      "\n",
      "Chunk 14: 'Show the values and morals in'\n",
      "\n",
      "Chunk 15: 'morals in in the daily life'\n",
      "\n",
      "Chunk 16: '.'\n",
      "\n",
      "Chunk 17: 'That is the lesson that we'\n",
      "\n",
      "Chunk 18: 'that we continue to pass on'\n",
      "\n",
      "Chunk 19: 'pass on to our son'\n",
      "\n",
      "Chunk 20: '.'\n",
      "\n",
      "Chunk 21: 'We need to pass those lessons'\n",
      "\n",
      "Chunk 22: 'lessons on to the many'\n",
      "\n",
      "Chunk 23: 'the many generations to'\n",
      "\n",
      "Chunk 24: 'to follow'\n",
      "\n",
      "Chunk 25: '.'\n",
      "\n",
      "Chunk 26: '[Cheering] Because we want'\n",
      "\n",
      "Chunk 27: 'we want our children in these'\n",
      "\n",
      "Chunk 28: 'in these nations to know that'\n",
      "\n",
      "Chunk 29: 'know that the only limit to'\n",
      "\n",
      "Chunk 30: 'limit to your achievement is'\n",
      "\n",
      "Chunk 31: 'is the strength of your'\n",
      "\n",
      "Chunk 32: 'of your dreams and your'\n",
      "\n",
      "Chunk 33: 'and your willingness to work'\n",
      "\n",
      "Chunk 34: 'to work for them'\n",
      "\n",
      "Chunk 35: '.'\n",
      "\n",
      "Chunk 36: 'Now is the winter of our'\n",
      "\n",
      "Chunk 37: 'of our discontent'\n",
      "\n",
      "Chunk 38: 'Made glorious summer by'\n",
      "\n",
      "Chunk 39: 'summer by this sun of York;'\n",
      "\n",
      "Chunk 40: 'And all the clouds that'\n",
      "\n",
      "Chunk 41: \"that lour'd upon our house\"\n",
      "\n",
      "Chunk 42: 'In the deep bosom of the'\n",
      "\n",
      "Chunk 43: 'of the ocean buried'\n",
      "\n",
      "Chunk 44: '.'\n",
      "\n",
      "Chunk 45: 'Now are our brows bound'\n",
      "\n",
      "Chunk 46: 'bound with victorious'\n",
      "\n",
      "Chunk 47: 'wreaths;'\n",
      "\n",
      "Chunk 48: 'Our bruised arms hung up'\n",
      "\n",
      "Chunk 49: 'hung up for monuments;'\n",
      "\n",
      "Chunk 50: 'Our stern alarums changed'\n",
      "\n",
      "Chunk 51: 'changed to merry meetings,'\n",
      "\n",
      "Chunk 52: 'Our dreadful marches to'\n",
      "\n",
      "Chunk 53: 'to delightful measures'\n",
      "\n",
      "Chunk 54: '.'\n",
      "\n",
      "Chunk 55: 'Grim-visaged war hath'\n",
      "\n",
      "Chunk 56: \"war hath smooth'd his\"\n",
      "\n",
      "Chunk 57: 'his wrinkled front;'\n",
      "\n",
      "Chunk 58: 'And now, instead of'\n",
      "\n",
      "Chunk 59: 'of mounting barded steeds'\n",
      "\n",
      "Chunk 60: 'To fright the souls of'\n",
      "\n",
      "Chunk 61: 'souls of fearful adversaries,'\n",
      "\n",
      "Chunk 62: 'He capers nimbly in a'\n",
      "\n",
      "Chunk 63: \"in a lady's chamber\"\n",
      "\n",
      "Chunk 64: 'To the lascivious pleasing'\n",
      "\n",
      "Chunk 65: 'pleasing of a lute'\n",
      "\n",
      "Chunk 66: '.'\n",
      "\n",
      "Chunk 67: 'But I, that am not shaped'\n",
      "\n",
      "Chunk 68: 'shaped for sportive tricks,'\n",
      "\n",
      "Chunk 69: 'Nor made to court an'\n",
      "\n",
      "Chunk 70: 'court an amorous'\n",
      "\n",
      "Chunk 71: 'amorous looking-glass;'\n",
      "\n",
      "Chunk 72: \"I, that am rudely stamp'd,\"\n",
      "\n",
      "Chunk 73: \"stamp'd, and want love's\"\n",
      "\n",
      "Chunk 74: \"love's majesty\"\n",
      "\n",
      "Chunk 75: 'To strut before a wanton'\n",
      "\n",
      "Chunk 76: 'a wanton ambling nymph;'\n",
      "\n",
      "Chunk 77: \"I, that am curtail'd of\"\n",
      "\n",
      "Chunk 78: 'of this fair proportion,'\n",
      "\n",
      "Chunk 79: 'Now is the winter of our'\n",
      "\n",
      "Chunk 80: 'of our discontent'\n",
      "\n",
      "Chunk 81: 'Made glorious summer by'\n",
      "\n",
      "Chunk 82: 'summer by this sun of York;'\n",
      "\n",
      "Chunk 83: 'And all the clouds that'\n",
      "\n",
      "Chunk 84: \"that lour'd upon our house\"\n",
      "\n",
      "Chunk 85: 'In the deep bosom of the'\n",
      "\n",
      "Chunk 86: 'of the ocean buried'\n",
      "\n",
      "Chunk 87: '.'\n",
      "\n",
      "Chunk 88: 'Now are our brows bound'\n",
      "\n",
      "Chunk 89: 'bound with victorious'\n",
      "\n",
      "Chunk 90: 'wreaths;'\n",
      "\n",
      "Chunk 91: 'Our bruised arms hung up'\n",
      "\n",
      "Chunk 92: 'hung up for monuments;'\n",
      "\n",
      "Chunk 93: 'Our stern alarums changed'\n",
      "\n",
      "Chunk 94: 'changed to merry meetings,'\n",
      "\n",
      "Chunk 95: 'Our dreadful marches to'\n",
      "\n",
      "Chunk 96: 'to delightful measures'\n",
      "\n",
      "Chunk 97: '.'\n",
      "\n",
      "Chunk 98: 'Grim-visaged war hath'\n",
      "\n",
      "Chunk 99: \"war hath smooth'd his\"\n",
      "\n",
      "Chunk 100: 'his wrinkled front;'\n",
      "\n",
      "Chunk 101: 'And now, instead of'\n",
      "\n",
      "Chunk 102: 'of mounting barded steeds'\n",
      "\n",
      "Chunk 103: 'To fright the souls of'\n",
      "\n",
      "Chunk 104: 'souls of fearful adversaries,'\n",
      "\n",
      "Chunk 105: 'He capers nimbly in a'\n",
      "\n",
      "Chunk 106: \"in a lady's chamber\"\n",
      "\n",
      "Chunk 107: 'To the lascivious pleasing'\n",
      "\n",
      "Chunk 108: 'pleasing of a lute'\n",
      "\n",
      "Chunk 109: '.'\n",
      "\n",
      "Chunk 110: 'But I, that am not shaped'\n",
      "\n",
      "Chunk 111: 'shaped for sportive tricks,'\n",
      "\n",
      "Chunk 112: 'Nor made to court an'\n",
      "\n",
      "Chunk 113: 'court an amorous'\n",
      "\n",
      "Chunk 114: 'amorous looking-glass;'\n",
      "\n",
      "Chunk 115: \"I, that am rudely stamp'd,\"\n",
      "\n",
      "Chunk 116: \"stamp'd, and want love's\"\n",
      "\n",
      "Chunk 117: \"love's majesty\"\n",
      "\n",
      "Chunk 118: 'To strut before a wanton'\n",
      "\n",
      "Chunk 119: 'a wanton ambling nymph;'\n",
      "\n",
      "Chunk 120: \"I, that am curtail'd of\"\n",
      "\n",
      "Chunk 121: 'of this fair proportion,'\n",
      "\n",
      "Chunk 122: 'Now is the winter of our'\n",
      "\n",
      "Chunk 123: 'of our discontent'\n",
      "\n",
      "Chunk 124: 'Made glorious summer by'\n",
      "\n",
      "Chunk 125: 'summer by this sun of York;'\n",
      "\n",
      "Chunk 126: 'And all the clouds that'\n",
      "\n",
      "Chunk 127: \"that lour'd upon our house\"\n",
      "\n",
      "Chunk 128: 'In the deep bosom of the'\n",
      "\n",
      "Chunk 129: 'of the ocean buried'\n",
      "\n",
      "Chunk 130: '.'\n",
      "\n",
      "Chunk 131: 'Now are our brows bound'\n",
      "\n",
      "Chunk 132: 'bound with victorious'\n",
      "\n",
      "Chunk 133: 'wreaths;'\n",
      "\n",
      "Chunk 134: 'Our bruised arms hung up'\n",
      "\n",
      "Chunk 135: 'hung up for monuments;'\n",
      "\n",
      "Chunk 136: 'Our stern alarums changed'\n",
      "\n",
      "Chunk 137: 'changed to merry meetings,'\n",
      "\n",
      "Chunk 138: 'Our dreadful marches to'\n",
      "\n",
      "Chunk 139: 'to delightful measures'\n",
      "\n",
      "Chunk 140: '.'\n",
      "\n",
      "Chunk 141: 'Grim-visaged war hath'\n",
      "\n",
      "Chunk 142: \"war hath smooth'd his\"\n",
      "\n",
      "Chunk 143: 'his wrinkled front;'\n",
      "\n",
      "Chunk 144: 'And now, instead of'\n",
      "\n",
      "Chunk 145: 'of mounting barded steeds'\n",
      "\n",
      "Chunk 146: 'To fright the souls of'\n",
      "\n",
      "Chunk 147: 'souls of fearful adversaries,'\n",
      "\n",
      "Chunk 148: 'He capers nimbly in a'\n",
      "\n",
      "Chunk 149: \"in a lady's chamber\"\n",
      "\n",
      "Chunk 150: 'To the lascivious pleasing'\n",
      "\n",
      "Chunk 151: 'pleasing of a lute'\n",
      "\n",
      "Chunk 152: '.'\n",
      "\n",
      "Chunk 153: 'But I, that am not shaped'\n",
      "\n",
      "Chunk 154: 'shaped for sportive tricks,'\n",
      "\n",
      "Chunk 155: 'Nor made to court an'\n",
      "\n",
      "Chunk 156: 'court an amorous'\n",
      "\n",
      "Chunk 157: 'amorous looking-glass;'\n",
      "\n",
      "Chunk 158: \"I, that am rudely stamp'd,\"\n",
      "\n",
      "Chunk 159: \"stamp'd, and want love's\"\n",
      "\n",
      "Chunk 160: \"love's majesty\"\n",
      "\n",
      "Chunk 161: 'To strut before a wanton'\n",
      "\n",
      "Chunk 162: 'a wanton ambling nymph;'\n",
      "\n",
      "Chunk 163: \"I, that am curtail'd of\"\n",
      "\n",
      "Chunk 164: 'of this fair proportion,'\n",
      "\n",
      "Chunk 165: 'Now is the winter of our'\n",
      "\n",
      "Chunk 166: 'of our discontent'\n",
      "\n",
      "Chunk 167: 'Made glorious summer by'\n",
      "\n",
      "Chunk 168: 'summer by this sun of York;'\n",
      "\n",
      "Chunk 169: 'And all the clouds that'\n",
      "\n",
      "Chunk 170: \"that lour'd upon our house\"\n",
      "\n",
      "Chunk 171: 'In the deep bosom of the'\n",
      "\n",
      "Chunk 172: 'of the ocean buried'\n",
      "\n",
      "Chunk 173: '.'\n",
      "\n",
      "Chunk 174: 'Now are our brows bound'\n",
      "\n",
      "Chunk 175: 'bound with victorious'\n",
      "\n",
      "Chunk 176: 'wreaths;'\n",
      "\n",
      "Chunk 177: 'Our bruised arms hung up'\n",
      "\n",
      "Chunk 178: 'hung up for monuments;'\n",
      "\n",
      "Chunk 179: 'Our stern alarums changed'\n",
      "\n",
      "Chunk 180: 'changed to merry meetings,'\n",
      "\n",
      "Chunk 181: 'Our dreadful marches to'\n",
      "\n",
      "Chunk 182: 'to delightful measures'\n",
      "\n",
      "Chunk 183: '.'\n",
      "\n",
      "Chunk 184: 'Grim-visaged war hath'\n",
      "\n",
      "Chunk 185: \"war hath smooth'd his\"\n",
      "\n",
      "Chunk 186: 'his wrinkled front;'\n",
      "\n",
      "Chunk 187: 'And now, instead of'\n",
      "\n",
      "Chunk 188: 'of mounting barded steeds'\n",
      "\n",
      "Chunk 189: 'To fright the souls of'\n",
      "\n",
      "Chunk 190: 'souls of fearful adversaries,'\n",
      "\n",
      "Chunk 191: 'He capers nimbly in a'\n",
      "\n",
      "Chunk 192: \"in a lady's chamber\"\n",
      "\n",
      "Chunk 193: 'To the lascivious pleasing'\n",
      "\n",
      "Chunk 194: 'pleasing of a lute'\n",
      "\n",
      "Chunk 195: '.'\n",
      "\n",
      "Chunk 196: 'But I, that am not shaped'\n",
      "\n",
      "Chunk 197: 'shaped for sportive tricks,'\n",
      "\n",
      "Chunk 198: 'Nor made to court an'\n",
      "\n",
      "Chunk 199: 'court an amorous'\n",
      "\n",
      "Chunk 200: 'amorous looking-glass;'\n",
      "\n",
      "Chunk 201: \"I, that am rudely stamp'd,\"\n",
      "\n",
      "Chunk 202: \"stamp'd, and want love's\"\n",
      "\n",
      "Chunk 203: \"love's majesty\"\n",
      "\n",
      "Chunk 204: 'To strut before a wanton'\n",
      "\n",
      "Chunk 205: 'a wanton ambling nymph;'\n",
      "\n",
      "Chunk 206: \"I, that am curtail'd of\"\n",
      "\n",
      "Chunk 207: 'of this fair proportion,'\n",
      "\n",
      "Chunk 208: 'docs = text_splitter'\n",
      "\n",
      "Chunk 209: '.split_documents(documents)'\n",
      "\n",
      "Chunk 210: '🕵️ What’s Likely Going Wrong?'\n",
      "\n",
      "Chunk 211: 'The chunk_size=20 with'\n",
      "\n",
      "Chunk 212: 'with chunk_overlap=5 is super'\n",
      "\n",
      "Chunk 213: 'is super small'\n",
      "\n",
      "Chunk 214: \". You're telling it to chop\"\n",
      "\n",
      "Chunk 215: 'to chop the text into tiny'\n",
      "\n",
      "Chunk 216: 'into tiny 20-character'\n",
      "\n",
      "Chunk 217: 'pieces, overlapping by 5'\n",
      "\n",
      "Chunk 218: 'by 5 characters'\n",
      "\n",
      "Chunk 219: '. But since your text isn’t'\n",
      "\n",
      "Chunk 220: 'isn’t massive, that’s likely'\n",
      "\n",
      "Chunk 221: 'likely resulting in only a'\n",
      "\n",
      "Chunk 222: 'in only a few chunks—maybe'\n",
      "\n",
      "Chunk 223: 'even less than 5'\n",
      "\n",
      "Chunk 224: '.'\n",
      "\n",
      "Chunk 225: 'Plus, it splits based on'\n",
      "\n",
      "Chunk 226: 'based on character count, not'\n",
      "\n",
      "Chunk 227: 'not sentences or paragraphs'\n",
      "\n",
      "Chunk 228: '.'\n",
      "\n",
      "Chunk 229: '🧪 Try This Instead: Use'\n",
      "\n",
      "Chunk 230: 'Use Larger Chunks'\n",
      "\n",
      "Chunk 231: '!'\n",
      "\n",
      "Chunk 232: 'Let’s beef it up a bit:'\n",
      "\n",
      "Chunk 233: 'Python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 234: 'from langchain_community'\n",
      "\n",
      "Chunk 235: '.document_loaders import'\n",
      "\n",
      "Chunk 236: 'import TextLoader'\n",
      "\n",
      "Chunk 237: 'from langchain_text_splitters'\n",
      "\n",
      "Chunk 238: 'import CharacterTextSplitter'\n",
      "\n",
      "Chunk 239: '# Load speech'\n",
      "\n",
      "Chunk 240: 'loader = TextLoader(\"Speech'\n",
      "\n",
      "Chunk 241: '.txt\")'\n",
      "\n",
      "Chunk 242: 'documents = loader.load()'\n",
      "\n",
      "Chunk 243: '# Use larger chunks to get'\n",
      "\n",
      "Chunk 244: 'to get more meaningful pieces'\n",
      "\n",
      "Chunk 245: 'text_splitter ='\n",
      "\n",
      "Chunk 246: 'CharacterTextSplitter(chunk_s'\n",
      "\n",
      "Chunk 247: 'er(chunk_size=200,'\n",
      "\n",
      "Chunk 248: 'chunk_overlap=50)'\n",
      "\n",
      "Chunk 249: 'docs = text_splitter'\n",
      "\n",
      "Chunk 250: '.split_documents(documents)'\n",
      "\n",
      "Chunk 251: '# Check number of splits'\n",
      "\n",
      "Chunk 252: 'print(f\"Total chunks:'\n",
      "\n",
      "Chunk 253: 'chunks: {len(docs)}\")'\n",
      "\n",
      "Chunk 254: 'for i, doc in'\n",
      "\n",
      "Chunk 255: 'i, doc in enumerate(docs):'\n",
      "\n",
      "Chunk 256: 'print(f\"\\\\n--- Chunk {i+1}'\n",
      "\n",
      "Chunk 257: '{i+1} ---\\\\n{doc'\n",
      "\n",
      "Chunk 258: '.page_content}\")'\n",
      "\n",
      "Chunk 259: '💡 Want Even Smarter Splitting'\n",
      "\n",
      "Chunk 260: '?'\n",
      "\n",
      "Chunk 261: \"If you're aiming for chunks\"\n",
      "\n",
      "Chunk 262: 'chunks that make more natural'\n",
      "\n",
      "Chunk 263: 'natural sense (like sentences'\n",
      "\n",
      "Chunk 264: 'sentences or paragraphs), try'\n",
      "\n",
      "Chunk 265: 'try using:'\n",
      "\n",
      "Chunk 266: 'Python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 267: 'from langchain_text_splitters'\n",
      "\n",
      "Chunk 268: 'import'\n",
      "\n",
      "Chunk 269: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 270: 'extSplitter'\n",
      "\n",
      "Chunk 271: 'text_splitter ='\n",
      "\n",
      "Chunk 272: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 273: 'extSplitter('\n",
      "\n",
      "Chunk 274: 'chunk_size=200,'\n",
      "\n",
      "Chunk 275: 'chunk_overlap=50,'\n",
      "\n",
      "Chunk 276: 'separators=[\"\\\\n\\\\n\", \"\\\\n\",'\n",
      "\n",
      "Chunk 277: '\"\\\\n\", \"'\n",
      "\n",
      "Chunk 278: '.\", \" \"]'\n",
      "\n",
      "Chunk 279: ')'\n",
      "\n",
      "Chunk 280: 'docs = text_splitter'\n",
      "\n",
      "Chunk 281: '.split_documents(documents)'\n",
      "\n",
      "Chunk 282: 'This will keep your splits a'\n",
      "\n",
      "Chunk 283: 'splits a bit more'\n",
      "\n",
      "Chunk 284: 'bit more human-readable and'\n",
      "\n",
      "Chunk 285: 'and context-aware'\n",
      "\n",
      "Chunk 286: '!'\n",
      "\n",
      "Chunk 287: '✅ Summary:'\n",
      "\n",
      "Chunk 288: 'chunk_size=20 is too'\n",
      "\n",
      "Chunk 289: 'is too small—use 200+ for'\n",
      "\n",
      "Chunk 290: '200+ for better results'\n",
      "\n",
      "Chunk 291: '.'\n",
      "\n",
      "Chunk 292: 'Use'\n",
      "\n",
      "Chunk 293: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 294: 'extSplitter'\n",
      "\n",
      "Chunk 295: 'if you want natural'\n",
      "\n",
      "Chunk 296: 'natural sentence/paragraph'\n",
      "\n",
      "Chunk 297: 'breaks'\n",
      "\n",
      "Chunk 298: '.'\n",
      "\n",
      "Chunk 299: 'split_documents() will always'\n",
      "\n",
      "Chunk 300: 'always return a list of'\n",
      "\n",
      "Chunk 301: 'a list of Document objects,'\n",
      "\n",
      "Chunk 302: 'objects, even for one file'\n",
      "\n",
      "Chunk 303: '.'\n",
      "\n",
      "Chunk 304: 'If you want to split multiple'\n",
      "\n",
      "Chunk 305: 'multiple files, use'\n",
      "\n",
      "Chunk 306: 'use DirectoryLoader instead'\n",
      "\n",
      "Chunk 307: 'instead of TextLoader'\n",
      "\n",
      "Chunk 308: '. Let me know if you need that'\n",
      "\n",
      "Chunk 309: 'need that too'\n",
      "\n",
      "Chunk 310: '!'\n",
      "\n",
      "Chunk 311: 'You said:\\naywhat does chunk'\n",
      "\n",
      "Chunk 312: '🧠 Real-Life Analogy: Netflix'\n",
      "\n",
      "Chunk 313: 'Netflix Series 🎬'\n",
      "\n",
      "Chunk 314: 'Imagine your speech is a'\n",
      "\n",
      "Chunk 315: 'is a story, and you want to'\n",
      "\n",
      "Chunk 316: 'want to split it into'\n",
      "\n",
      "Chunk 317: 'it into episodes'\n",
      "\n",
      "Chunk 318: '.'\n",
      "\n",
      "Chunk 319: 'chunk_size = how long each'\n",
      "\n",
      "Chunk 320: 'long each episode is'\n",
      "\n",
      "Chunk 321: 'chunk_overlap = the'\n",
      "\n",
      "Chunk 322: '= the “Previously on…” intro'\n",
      "\n",
      "Chunk 323: 'intro at the beginning of'\n",
      "\n",
      "Chunk 324: 'of each new episode'\n",
      "\n",
      "Chunk 325: '🔎 Why overlap matters?'\n",
      "\n",
      "Chunk 326: 'If an important sentence is'\n",
      "\n",
      "Chunk 327: 'is cut in the middle, overlap'\n",
      "\n",
      "Chunk 328: 'overlap helps the next chunk'\n",
      "\n",
      "Chunk 329: 'chunk pick it up smoothly so'\n",
      "\n",
      "Chunk 330: 'so the model doesn’t get'\n",
      "\n",
      "Chunk 331: 'get confused'\n",
      "\n",
      "Chunk 332: '.'\n",
      "\n",
      "Chunk 333: '🧪 Example:'\n",
      "\n",
      "Chunk 334: 'Let’s say we have this short'\n",
      "\n",
      "Chunk 335: 'short text:'\n",
      "\n",
      "Chunk 336: '“My parents impressed on me'\n",
      "\n",
      "Chunk 337: 'on me the value that you work'\n",
      "\n",
      "Chunk 338: 'you work hard for what you'\n",
      "\n",
      "Chunk 339: 'what you want in life'\n",
      "\n",
      "Chunk 340: '.”'\n",
      "\n",
      "Chunk 341: 'Case 1: Small chunk size, no'\n",
      "\n",
      "Chunk 342: 'size, no overlap'\n",
      "\n",
      "Chunk 343: 'Python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 344: 'Copy\\nEdit\\nchunk_size = 20'\n",
      "\n",
      "Chunk 345: 'chunk_overlap = 0\\nChunks:'\n",
      "\n",
      "Chunk 346: '“My parents impress”'\n",
      "\n",
      "Chunk 347: '“ed on me the value”'\n",
      "\n",
      "Chunk 348: '“ that you work har”'\n",
      "\n",
      "Chunk 349: '“d for what you wan”'\n",
      "\n",
      "Chunk 350: '“t in life.”'\n",
      "\n",
      "Chunk 351: 'Result: You may lose meaning'\n",
      "\n",
      "Chunk 352: 'meaning because'\n",
      "\n",
      "Chunk 353: 'because words/sentences are'\n",
      "\n",
      "Chunk 354: 'are broken'\n",
      "\n",
      "Chunk 355: '.'\n",
      "\n",
      "Chunk 356: 'Case 2: Bigger chunk with'\n",
      "\n",
      "Chunk 357: 'with overlap'\n",
      "\n",
      "Chunk 358: 'Python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 359: 'Copy\\nEdit\\nchunk_size = 40'\n",
      "\n",
      "Chunk 360: 'chunk_overlap = 10\\nChunks:'\n",
      "\n",
      "Chunk 361: '“My parents impressed on me'\n",
      "\n",
      "Chunk 362: 'on me the value that yo”'\n",
      "\n",
      "Chunk 363: '“value that you work hard for'\n",
      "\n",
      "Chunk 364: 'hard for what you want ”'\n",
      "\n",
      "Chunk 365: '“what you want in life.”'\n",
      "\n",
      "Chunk 366: 'Now, chunks carry better'\n",
      "\n",
      "Chunk 367: 'better continuity and'\n",
      "\n",
      "Chunk 368: 'and preserve meaning'\n",
      "\n",
      "Chunk 369: '.'\n",
      "\n",
      "Chunk 370: '🛠️ When to Use What?'\n",
      "\n",
      "Chunk 371: 'Use'\n",
      "\n",
      "Chunk 372: 'Case\\tchunk_size\\tchunk_overlap'\n",
      "\n",
      "Chunk 373: 'Tiny docs\\tsmall'\n",
      "\n",
      "Chunk 374: '(100–200)\\t10–20'\n",
      "\n",
      "Chunk 375: 'Long speeches/books\\tbig'\n",
      "\n",
      "Chunk 376: '(500–1000)\\t50–100'\n",
      "\n",
      "Chunk 377: 'QA over documents\\tmedium'\n",
      "\n",
      "Chunk 378: '(300–600)\\t50'\n",
      "\n",
      "Chunk 379: 'Sentence-sensitive'\n",
      "\n",
      "Chunk 380: 'tasks\\tsmall\\tmedium'\n",
      "\n",
      "Chunk 381: '🧁 TL;DR – Key Takeaways'\n",
      "\n",
      "Chunk 382: 'chunk_size = how big each'\n",
      "\n",
      "Chunk 383: 'big each text piece is'\n",
      "\n",
      "Chunk 384: 'chunk_overlap = how much text'\n",
      "\n",
      "Chunk 385: 'much text is shared between'\n",
      "\n",
      "Chunk 386: 'between chunks'\n",
      "\n",
      "Chunk 387: 'Small chunks: easier to'\n",
      "\n",
      "Chunk 388: 'easier to process, but may'\n",
      "\n",
      "Chunk 389: 'but may lose context'\n",
      "\n",
      "Chunk 390: 'Big chunks: preserve meaning,'\n",
      "\n",
      "Chunk 391: 'meaning, but take more memory'\n",
      "\n",
      "Chunk 392: 'Overlap: preserves flow'\n",
      "\n",
      "Chunk 393: 'flow between chunks'\n",
      "\n",
      "Chunk 394: 'Let me know if you want a'\n",
      "\n",
      "Chunk 395: 'want a visual image or'\n",
      "\n",
      "Chunk 396: 'image or diagram to'\n",
      "\n",
      "Chunk 397: 'to understand it better—I’ll'\n",
      "\n",
      "Chunk 398: 'whip one up'\n",
      "\n",
      "Chunk 399: '! 😄'\n",
      "\n",
      "Chunk 400: 'You said:'\n",
      "\n",
      "Chunk 401: 'Case 1: Small chunk size, no'\n",
      "\n",
      "Chunk 402: 'size, no overlap'\n",
      "\n",
      "Chunk 403: 'Python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 404: 'Copy\\nEdit\\nchunk_size = 20'\n",
      "\n",
      "Chunk 405: 'chunk_overlap = 0\\nChunks:'\n",
      "\n",
      "Chunk 406: '“My parents impress”'\n",
      "\n",
      "Chunk 407: '“ed on me the value”'\n",
      "\n",
      "Chunk 408: '“ that you work har”'\n",
      "\n",
      "Chunk 409: '“d for what you wan”'\n",
      "\n",
      "Chunk 410: '“t in life'\n",
      "\n",
      "Chunk 411: \".”I don't think the chunk size\"\n",
      "\n",
      "Chunk 412: 'size here is 20'\n",
      "\n",
      "Chunk 413: '.'\n",
      "\n",
      "Chunk 414: 'ChatGPT said:'\n",
      "\n",
      "Chunk 415: \"You're absolutely right,\"\n",
      "\n",
      "Chunk 416: 'right, detective'\n",
      "\n",
      "Chunk 417: '! 🕵️\\u200d♂️ Great catch — that'\n",
      "\n",
      "Chunk 418: '— that example did not'\n",
      "\n",
      "Chunk 419: 'did not accurately show'\n",
      "\n",
      "Chunk 420: 'show chunks of size 20'\n",
      "\n",
      "Chunk 421: 'size 20 characters'\n",
      "\n",
      "Chunk 422: \". Let's fix that with real and\"\n",
      "\n",
      "Chunk 423: 'real and precise math like'\n",
      "\n",
      "Chunk 424: 'math like good AI engineers 😎'\n",
      "\n",
      "Chunk 425: '.'\n",
      "\n",
      "Chunk 426: '🧮 Corrected Example:'\n",
      "\n",
      "Chunk 427: 'Let’s take this sentence:'\n",
      "\n",
      "Chunk 428: '\"My parents impressed on me'\n",
      "\n",
      "Chunk 429: 'on me the value that you work'\n",
      "\n",
      "Chunk 430: 'you work hard for what you'\n",
      "\n",
      "Chunk 431: 'what you want in life'\n",
      "\n",
      "Chunk 432: '.\"'\n",
      "\n",
      "Chunk 433: 'This sentence has 92'\n",
      "\n",
      "Chunk 434: 'has 92 characters (including'\n",
      "\n",
      "Chunk 435: 'spaces and punctuation)'\n",
      "\n",
      "Chunk 436: '.'\n",
      "\n",
      "Chunk 437: 'Now let’s split it correctly'\n",
      "\n",
      "Chunk 438: 'correctly using:'\n",
      "\n",
      "Chunk 439: 'python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 440: 'Copy\\nEdit\\nchunk_size = 20'\n",
      "\n",
      "Chunk 441: 'chunk_overlap = 0'\n",
      "\n",
      "Chunk 442: '✅ Real Chunks (each = 20'\n",
      "\n",
      "Chunk 443: '= 20 characters):'\n",
      "\n",
      "Chunk 444: '\"My parents impresse\" → 20'\n",
      "\n",
      "Chunk 445: '→ 20 characters'\n",
      "\n",
      "Chunk 446: '\"d on me the value t\" → next'\n",
      "\n",
      "Chunk 447: 't\" → next 20 characters'\n",
      "\n",
      "Chunk 448: '\"hat you work hard f\"'\n",
      "\n",
      "Chunk 449: '\"or what you want in\"'\n",
      "\n",
      "Chunk 450: '\" life'\n",
      "\n",
      "Chunk 451: '.\" → last remaining characters'\n",
      "\n",
      "Chunk 452: '(less than 20)'\n",
      "\n",
      "Chunk 453: '✅ Now it’s accurate!'\n",
      "\n",
      "Chunk 454: '⚠️ Why It Matters'\n",
      "\n",
      "Chunk 455: \"When you're using\"\n",
      "\n",
      "Chunk 456: 'using CharacterTextSplitter,'\n",
      "\n",
      "Chunk 457: 'it slices your text based on'\n",
      "\n",
      "Chunk 458: 'based on character count, not'\n",
      "\n",
      "Chunk 459: 'not words or sentences —'\n",
      "\n",
      "Chunk 460: '— unless you use other'\n",
      "\n",
      "Chunk 461: 'use other splitters like'\n",
      "\n",
      "Chunk 462: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 463: 'extSplitter'\n",
      "\n",
      "Chunk 464: 'or SentenceTextSplitter'\n",
      "\n",
      "Chunk 465: '.'\n",
      "\n",
      "Chunk 466: 'So, setting chunk_size=20'\n",
      "\n",
      "Chunk 467: 'tells it:'\n",
      "\n",
      "Chunk 468: '“Hey LangChain, give me 20'\n",
      "\n",
      "Chunk 469: 'me 20 characters per slice,'\n",
      "\n",
      "Chunk 470: 'slice, and don’t repeat'\n",
      "\n",
      "Chunk 471: 'repeat anything if overlap ='\n",
      "\n",
      "Chunk 472: 'overlap = 0'\n",
      "\n",
      "Chunk 473: '.”'\n",
      "\n",
      "Chunk 474: '💡 Pro Tip'\n",
      "\n",
      "Chunk 475: 'To split by sentences or'\n",
      "\n",
      "Chunk 476: 'or smartly, use this instead:'\n",
      "\n",
      "Chunk 477: 'python\\nCopy\\nEdit'\n",
      "\n",
      "Chunk 478: 'from langchain_text_splitters'\n",
      "\n",
      "Chunk 479: 'import'\n",
      "\n",
      "Chunk 480: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 481: 'extSplitter'\n",
      "\n",
      "Chunk 482: 'text_splitter ='\n",
      "\n",
      "Chunk 483: 'RecursiveCharacterTextSplitte'\n",
      "\n",
      "Chunk 484: 'extSplitter('\n",
      "\n",
      "Chunk 485: 'chunk_size=100,'\n",
      "\n",
      "Chunk 486: 'chunk_overlap=20,'\n",
      "\n",
      "Chunk 487: 'separators=[\"\\\\n\\\\n\", \"\\\\n\",'\n",
      "\n",
      "Chunk 488: '\"\\\\n\", \"'\n",
      "\n",
      "Chunk 489: '.\", \"!\", \"?\", \" \", \"\"]'\n",
      "\n",
      "Chunk 490: ')'\n",
      "\n",
      "Chunk 491: 'This tries to break at'\n",
      "\n",
      "Chunk 492: 'break at sentence ends or'\n",
      "\n",
      "Chunk 493: 'ends or spaces, avoiding'\n",
      "\n",
      "Chunk 494: 'avoiding weird cuts in the'\n",
      "\n",
      "Chunk 495: 'in the middle of words like'\n",
      "\n",
      "Chunk 496: 'like \"value t\"'\n",
      "\n",
      "Chunk 497: '.'\n",
      "\n",
      "Chunk 498: \"Let me know if you'd like to\"\n",
      "\n",
      "Chunk 499: 'like to compare word-based or'\n",
      "\n",
      "Chunk 500: 'or sentence-based chunking'\n",
      "\n",
      "Chunk 501: 'chunking too'\n",
      "\n",
      "Chunk 502: '! I’ll chunk your worries away'\n",
      "\n",
      "Chunk 503: 'away 😄✨'\n",
      "\n",
      "Chunk 504: 'Tools'\n",
      "\n",
      "Chunk 505: 'ChatGPT can make mistakes'\n",
      "\n",
      "Chunk 506: '. Check important info'\n",
      "\n",
      "Chunk 507: '. See Cookie Preferences.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load your speech\n",
    "loader = TextLoader(\"Speech.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Use Recursive splitter with forced small chunk size\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=30,\n",
    "    chunk_overlap=10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"],  # Include char-level fallback\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print chunks\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nChunk {i+1}: {repr(doc.page_content)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ba06c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Speech.txt'}, page_content='My parents impressed on me the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='on me the value of that you'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='that you work hard for what'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='for what you want in life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='That your word is your bond'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='your bond and you do what you'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='what you say and keep your'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='keep your promise'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='That you treat people with'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='with respect'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Show the values and morals in'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='morals in in the daily life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='That is the lesson that we'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='that we continue to pass on'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pass on to our son'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='We need to pass those lessons'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='lessons on to the many'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='the many generations to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to follow'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='[Cheering] Because we want'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='we want our children in these'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='in these nations to know that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='know that the only limit to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='limit to your achievement is'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='is the strength of your'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of your dreams and your'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='and your willingness to work'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to work for them'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now is the winter of our'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of our discontent'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Made glorious summer by'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='summer by this sun of York;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And all the clouds that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"that lour'd upon our house\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='In the deep bosom of the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of the ocean buried'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now are our brows bound'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='bound with victorious'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='wreaths;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our bruised arms hung up'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our stern alarums changed'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='changed to merry meetings,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our dreadful marches to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to delightful measures'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Grim-visaged war hath'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"war hath smooth'd his\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='his wrinkled front;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And now, instead of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of mounting barded steeds'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To fright the souls of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='souls of fearful adversaries,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='He capers nimbly in a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"in a lady's chamber\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To the lascivious pleasing'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pleasing of a lute'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='But I, that am not shaped'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='shaped for sportive tricks,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Nor made to court an'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='court an amorous'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='amorous looking-glass;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am rudely stamp'd,\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"stamp'd, and want love's\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"love's majesty\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To strut before a wanton'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='a wanton ambling nymph;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am curtail'd of\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of this fair proportion,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now is the winter of our'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of our discontent'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Made glorious summer by'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='summer by this sun of York;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And all the clouds that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"that lour'd upon our house\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='In the deep bosom of the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of the ocean buried'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now are our brows bound'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='bound with victorious'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='wreaths;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our bruised arms hung up'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our stern alarums changed'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='changed to merry meetings,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our dreadful marches to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to delightful measures'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Grim-visaged war hath'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"war hath smooth'd his\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='his wrinkled front;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And now, instead of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of mounting barded steeds'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To fright the souls of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='souls of fearful adversaries,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='He capers nimbly in a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"in a lady's chamber\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To the lascivious pleasing'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pleasing of a lute'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='But I, that am not shaped'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='shaped for sportive tricks,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Nor made to court an'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='court an amorous'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='amorous looking-glass;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am rudely stamp'd,\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"stamp'd, and want love's\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"love's majesty\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To strut before a wanton'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='a wanton ambling nymph;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am curtail'd of\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of this fair proportion,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now is the winter of our'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of our discontent'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Made glorious summer by'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='summer by this sun of York;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And all the clouds that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"that lour'd upon our house\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='In the deep bosom of the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of the ocean buried'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now are our brows bound'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='bound with victorious'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='wreaths;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our bruised arms hung up'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our stern alarums changed'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='changed to merry meetings,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our dreadful marches to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to delightful measures'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Grim-visaged war hath'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"war hath smooth'd his\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='his wrinkled front;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And now, instead of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of mounting barded steeds'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To fright the souls of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='souls of fearful adversaries,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='He capers nimbly in a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"in a lady's chamber\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To the lascivious pleasing'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pleasing of a lute'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='But I, that am not shaped'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='shaped for sportive tricks,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Nor made to court an'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='court an amorous'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='amorous looking-glass;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am rudely stamp'd,\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"stamp'd, and want love's\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"love's majesty\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To strut before a wanton'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='a wanton ambling nymph;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am curtail'd of\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of this fair proportion,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now is the winter of our'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of our discontent'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Made glorious summer by'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='summer by this sun of York;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And all the clouds that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"that lour'd upon our house\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='In the deep bosom of the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of the ocean buried'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now are our brows bound'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='bound with victorious'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='wreaths;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our bruised arms hung up'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our stern alarums changed'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='changed to merry meetings,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Our dreadful marches to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to delightful measures'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Grim-visaged war hath'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"war hath smooth'd his\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='his wrinkled front;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='And now, instead of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of mounting barded steeds'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To fright the souls of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='souls of fearful adversaries,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='He capers nimbly in a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"in a lady's chamber\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To the lascivious pleasing'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pleasing of a lute'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='But I, that am not shaped'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='shaped for sportive tricks,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Nor made to court an'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='court an amorous'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='amorous looking-glass;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am rudely stamp'd,\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"stamp'd, and want love's\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"love's majesty\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To strut before a wanton'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='a wanton ambling nymph;'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"I, that am curtail'd of\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of this fair proportion,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='docs = text_splitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.split_documents(documents)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🕵️ What’s Likely Going Wrong?'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='The chunk_size=20 with'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='with chunk_overlap=5 is super'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='is super small'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\". You're telling it to chop\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to chop the text into tiny'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='into tiny 20-character'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='pieces, overlapping by 5'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='by 5 characters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='. But since your text isn’t'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='isn’t massive, that’s likely'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='likely resulting in only a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='in only a few chunks—maybe'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='even less than 5'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Plus, it splits based on'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='based on character count, not'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='not sentences or paragraphs'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🧪 Try This Instead: Use'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Use Larger Chunks'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='!'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Let’s beef it up a bit:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='from langchain_community'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.document_loaders import'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='import TextLoader'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='from langchain_text_splitters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='import CharacterTextSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='# Load speech'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='loader = TextLoader(\"Speech'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.txt\")'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='documents = loader.load()'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='# Use larger chunks to get'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to get more meaningful pieces'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='text_splitter ='),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='CharacterTextSplitter(chunk_s'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='er(chunk_size=200,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap=50)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='docs = text_splitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.split_documents(documents)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='# Check number of splits'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='print(f\"Total chunks:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunks: {len(docs)}\")'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='for i, doc in'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='i, doc in enumerate(docs):'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='print(f\"\\\\n--- Chunk {i+1}'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='{i+1} ---\\\\n{doc'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.page_content}\")'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='💡 Want Even Smarter Splitting'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='?'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"If you're aiming for chunks\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunks that make more natural'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='natural sense (like sentences'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='sentences or paragraphs), try'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='try using:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='from langchain_text_splitters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='import'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='text_splitter ='),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter('),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_size=200,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap=50,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='separators=[\"\\\\n\\\\n\", \"\\\\n\",'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"\\\\n\", \"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.\", \" \"]'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=')'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='docs = text_splitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.split_documents(documents)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='This will keep your splits a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='splits a bit more'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='bit more human-readable and'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='and context-aware'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='!'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='✅ Summary:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_size=20 is too'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='is too small—use 200+ for'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='200+ for better results'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Use'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='if you want natural'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='natural sentence/paragraph'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='breaks'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='split_documents() will always'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='always return a list of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='a list of Document objects,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='objects, even for one file'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='If you want to split multiple'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='multiple files, use'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='use DirectoryLoader instead'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='instead of TextLoader'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='. Let me know if you need that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='need that too'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='!'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='You said:\\naywhat does chunk'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🧠 Real-Life Analogy: Netflix'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Netflix Series 🎬'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Imagine your speech is a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='is a story, and you want to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='want to split it into'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='it into episodes'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_size = how long each'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='long each episode is'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='= the “Previously on…” intro'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='intro at the beginning of'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='of each new episode'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🔎 Why overlap matters?'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='If an important sentence is'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='is cut in the middle, overlap'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='overlap helps the next chunk'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk pick it up smoothly so'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='so the model doesn’t get'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='get confused'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🧪 Example:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Let’s say we have this short'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='short text:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“My parents impressed on me'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='on me the value that you work'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='you work hard for what you'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='what you want in life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Case 1: Small chunk size, no'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='size, no overlap'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Copy\\nEdit\\nchunk_size = 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = 0\\nChunks:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“My parents impress”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“ed on me the value”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“ that you work har”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“d for what you wan”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“t in life.”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Result: You may lose meaning'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='meaning because'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='because words/sentences are'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='are broken'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Case 2: Bigger chunk with'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='with overlap'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Copy\\nEdit\\nchunk_size = 40'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = 10\\nChunks:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“My parents impressed on me'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='on me the value that yo”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“value that you work hard for'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='hard for what you want ”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“what you want in life.”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now, chunks carry better'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='better continuity and'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='and preserve meaning'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🛠️ When to Use What?'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Use'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Case\\tchunk_size\\tchunk_overlap'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Tiny docs\\tsmall'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='(100–200)\\t10–20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Long speeches/books\\tbig'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='(500–1000)\\t50–100'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='QA over documents\\tmedium'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='(300–600)\\t50'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Sentence-sensitive'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='tasks\\tsmall\\tmedium'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🧁 TL;DR – Key Takeaways'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_size = how big each'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='big each text piece is'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = how much text'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='much text is shared between'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='between chunks'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Small chunks: easier to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='easier to process, but may'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='but may lose context'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Big chunks: preserve meaning,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='meaning, but take more memory'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Overlap: preserves flow'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='flow between chunks'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Let me know if you want a'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='want a visual image or'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='image or diagram to'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='to understand it better—I’ll'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='whip one up'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='! 😄'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='You said:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Case 1: Small chunk size, no'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='size, no overlap'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Copy\\nEdit\\nchunk_size = 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = 0\\nChunks:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“My parents impress”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“ed on me the value”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“ that you work har”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“d for what you wan”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“t in life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\".”I don't think the chunk size\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='size here is 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='ChatGPT said:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"You're absolutely right,\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='right, detective'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='! 🕵️\\u200d♂️ Great catch — that'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='— that example did not'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='did not accurately show'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='show chunks of size 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='size 20 characters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\". Let's fix that with real and\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='real and precise math like'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='math like good AI engineers 😎'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='🧮 Corrected Example:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Let’s take this sentence:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"My parents impressed on me'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='on me the value that you work'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='you work hard for what you'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='what you want in life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.\"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='This sentence has 92'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='has 92 characters (including'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='spaces and punctuation)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Now let’s split it correctly'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='correctly using:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Copy\\nEdit\\nchunk_size = 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap = 0'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='✅ Real Chunks (each = 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='= 20 characters):'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"My parents impresse\" → 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='→ 20 characters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"d on me the value t\" → next'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='t\" → next 20 characters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"hat you work hard f\"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"or what you want in\"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\" life'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.\" → last remaining characters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='(less than 20)'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='✅ Now it’s accurate!'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='⚠️ Why It Matters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"When you're using\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='using CharacterTextSplitter,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='it slices your text based on'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='based on character count, not'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='not words or sentences —'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='— unless you use other'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='use other splitters like'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='or SentenceTextSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='So, setting chunk_size=20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='tells it:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='“Hey LangChain, give me 20'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='me 20 characters per slice,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='slice, and don’t repeat'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='repeat anything if overlap ='),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='overlap = 0'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.”'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='💡 Pro Tip'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='To split by sentences or'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='or smartly, use this instead:'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='python\\nCopy\\nEdit'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='from langchain_text_splitters'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='import'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='text_splitter ='),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='RecursiveCharacterTextSplitte'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='extSplitter('),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_size=100,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunk_overlap=20,'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='separators=[\"\\\\n\\\\n\", \"\\\\n\",'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='\"\\\\n\", \"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.\", \"!\", \"?\", \" \", \"\"]'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=')'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='This tries to break at'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='break at sentence ends or'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='ends or spaces, avoiding'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='avoiding weird cuts in the'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='in the middle of words like'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='like \"value t\"'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='.'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content=\"Let me know if you'd like to\"),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='like to compare word-based or'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='or sentence-based chunking'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='chunking too'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='! I’ll chunk your worries away'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='away 😄✨'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='Tools'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='ChatGPT can make mistakes'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='. Check important info'),\n",
       " Document(metadata={'source': 'Speech.txt'}, page_content='. See Cookie Preferences.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a7868da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5bbc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d5924ef4-5751-4363-965f-8121a447e3e9', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='13abdfc3-3b88-44c9-8013-6948c2ba89c3', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='20a4080e-a44f-4600-8869-48fd8165a93e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='b209e602-76f1-43e6-b0ff-188fcb846b8e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What hung up for the monuments ?\"\n",
    "docs=db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94882bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d5924ef4-5751-4363-965f-8121a447e3e9', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='13abdfc3-3b88-44c9-8013-6948c2ba89c3', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='20a4080e-a44f-4600-8869-48fd8165a93e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='b209e602-76f1-43e6-b0ff-188fcb846b8e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd4249",
   "metadata": {},
   "source": [
    "# Similarity Search with Scores , one of good methods in FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed61f63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='d5924ef4-5751-4363-965f-8121a447e3e9', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       "  167.34337),\n",
       " (Document(id='13abdfc3-3b88-44c9-8013-6948c2ba89c3', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       "  167.34337),\n",
       " (Document(id='20a4080e-a44f-4600-8869-48fd8165a93e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       "  167.34337),\n",
       " (Document(id='b209e602-76f1-43e6-b0ff-188fcb846b8e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       "  167.34337)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score = db.similarity_search_with_score(query)\n",
    "docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3da2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector for query: [1.17205810546875, 1.142122507095337, -4.341152667999268, -1.7983425855636597, 0.6705060005187988, 1.302890419960022, 0.0012621202040463686, 0.6011227369308472, 0.3053220510482788, 0.546068012714386, -0.9560771584510803, 0.4757692813873291, 0.960134744644165, -0.28709977865219116, 0.6079282760620117, -1.1685179471969604, 0.4097599983215332, -0.0730801373720169, -0.05072418972849846, 0.6032628417015076, 0.2823358178138733, -0.6929592490196228, -0.6936702728271484, 0.6055915355682373, -0.16918008029460907, 1.3742448091506958, 1.0249452590942383, -0.38615682721138, -0.3200676143169403, 0.9695039987564087, 0.1495586633682251, -0.6352800130844116, -1.063223958015442, -0.4771924614906311, 0.6998236775398254, -1.0063878297805786, 1.5329149961471558, 0.8393277525901794, 1.7349153757095337, -0.6875868439674377, 0.9125422239303589, -0.2728612720966339, -2.16859769821167, -0.06265021115541458, 0.5411943793296814, -0.9247835874557495, 0.6270304322242737, 1.192946195602417, 1.1340752840042114, -0.41848886013031006, 0.31226956844329834, -1.3875497579574585, -0.21391503512859344, -0.6749021410942078, 0.49248233437538147, 0.6762380599975586, 1.2704002857208252, 0.3971530497074127, 0.4542405307292938, 1.5485644340515137, 1.4666920900344849, -0.28981471061706543, 0.09123495221138, 0.565715491771698, 0.5172067880630493, -0.9747032523155212, -0.7373394966125488, 0.010463532991707325, 0.5273945331573486, -0.04153743013739586, 0.5180342793464661, 0.2605460286140442, 1.5592186450958252, -1.3801366090774536, -1.7856634855270386, 1.099989891052246, -0.25581425428390503, -0.4289856553077698, -0.3527374267578125, -0.1783611923456192, -0.18801897764205933, -0.5877825617790222, 1.5451973676681519, 0.7586522102355957, -0.0630403384566307, 1.6036890745162964, 0.5052846670150757, 0.935455322265625, -1.6501734256744385, 1.3829699754714966, 0.19989672303199768, -0.7741668820381165, -0.6112774014472961, 1.4185422658920288, -1.3249568939208984, 0.6298575401306152, -0.013466596603393555, -0.1787823587656021, -1.454280972480774, -0.6394249200820923, -0.45500892400741577, -0.24799387156963348, -1.0644835233688354, -0.5492251515388489, 1.3229289054870605, 1.062784194946289, 0.6500473022460938, 0.4395001530647278, -0.4324100613594055, 0.05495327711105347, -0.9400730729103088, 0.5523252487182617, -0.1947234869003296, -1.0642670392990112, 0.0027083605527877808, -1.0826938152313232, 0.3541453182697296, -1.2800551652908325, 1.295873761177063, -0.6988717913627625, -0.12840010225772858, -0.7812994718551636, -0.28490954637527466, 0.5512746572494507, -0.40997275710105896, 0.8097782135009766, -0.46669018268585205, 0.30785036087036133, 0.5263227820396423, -1.3938826322555542, 0.18579280376434326, -0.31281328201293945, -0.4681991934776306, -0.2729244530200958, -0.18524934351444244, 0.10344072431325912, -0.8409129977226257, -1.2438637018203735, -0.42068716883659363, 0.3079240322113037, 0.6403658986091614, -0.7484318017959595, 0.39076513051986694, -0.3793157935142517, 0.3474273085594177, 0.6883234977722168, 2.2165980339050293, -1.2456681728363037, 0.26409655809402466, -0.6002349257469177, 0.42182493209838867, 0.9602888226509094, 0.5716970562934875, -0.2592056095600128, 0.26415592432022095, -0.8134821653366089, -0.3485012650489807, -1.1150989532470703, -0.17426303029060364, 0.6405471563339233, 0.5948240160942078, 0.8141728043556213, -0.5585651993751526, 0.8503216505050659, 0.32185864448547363, -0.923483669757843, 0.875135600566864, 1.4567296504974365, 0.03222246095538139, 0.41351571679115295, -0.411808580160141, -1.01613450050354, -0.2971951365470886, -0.1916797161102295, 0.4357440173625946, -0.8133999705314636, 0.11552468687295914, -0.4093029201030731, 0.7858831286430359, -0.7068852782249451, 1.2296476364135742, -0.7071340084075928, 0.2536241412162781, 0.7582342624664307, -1.0758485794067383, 0.27719905972480774, -0.4665805995464325, 0.5730395317077637, -0.9882187843322754, -0.4120333790779114, -0.42832452058792114, 0.7063992619514465, -0.7645273804664612, 0.5801597833633423, -1.4103327989578247, -0.5225013494491577, 0.8494304418563843, 0.7712822556495667, 1.4648760557174683, -0.2721686065196991, -0.27739793062210083, 0.04078870639204979, 0.9844739437103271, 0.40419602394104004, -1.2009162902832031, 0.9291538596153259, -0.4608311057090759, 0.7431413531303406, -0.5373054146766663, -0.43794578313827515, 0.21322843432426453, -0.27915990352630615, 0.20498310029506683, -0.1493312120437622, 0.07962442189455032, -1.1334363222122192, -0.06955772638320923, 0.27467939257621765, -0.4601040780544281, -0.4404923915863037, -0.7243591547012329, 0.11444803327322006, -0.8774710893630981, -0.5300325155258179, 1.175063967704773, 0.31758689880371094, 0.039629943668842316, -0.6249445080757141, 0.09594156593084335, -0.04983488842844963, -0.6389281153678894, -1.5103120803833008, 0.8774296641349792, 0.854874849319458, -0.3097337484359741, -0.11363111436367035, 0.6806131601333618, 0.5027945041656494, 0.7926331758499146, 1.0499060153961182, -1.0403929948806763, -0.09663696587085724, 0.15727101266384125, -2.20015549659729, -0.917068600654602, 1.4875582456588745, 0.822199821472168, 0.2501547038555145, -0.18630661070346832, 0.43505966663360596, -0.14460770785808563, 0.4706655740737915, 0.463824063539505, 0.3012595474720001, 0.6238779425621033, -0.5802451968193054, -0.5977349877357483, -0.27707889676094055, -0.08905106037855148, -0.2620704174041748, 0.6445907354354858, -1.9971673488616943, 0.4535464644432068, -1.2294031381607056, -0.32940372824668884, -0.49880900979042053, -0.5960025787353516, -0.14797969162464142, 0.9491809606552124, -0.7396916151046753, 0.16287066042423248, 1.4489954710006714, 0.19697709381580353, 0.8898030519485474, -0.18518520891666412, -0.5103060007095337, -0.16195523738861084, -0.788561224937439, -0.6470053195953369, 0.4401482939720154, -0.41729870438575745, 0.9689606428146362, -1.5409090518951416, -0.18939676880836487, -1.2610368728637695, 0.3415254056453705, 0.4024735689163208, -0.22851069271564484, 0.46031972765922546, -0.3977512717247009, 0.25655585527420044, 0.42556554079055786, -0.5745558738708496, -0.1303248107433319, -0.5711906552314758, 0.20572833716869354, 0.3812037706375122, -1.2889131307601929, -0.18089525401592255, -0.6527462005615234, 1.0194519758224487, -0.6469191908836365, 0.5102506875991821, 1.0771681070327759, 0.5694044828414917, -0.037961166352033615, 1.574575662612915, -0.12553927302360535, 0.7911919355392456, -0.4474424719810486, -0.4352332353591919, 0.3062797486782074, 0.5279109477996826, -0.07443299889564514, -1.5214786529541016, 1.0257115364074707, 0.9424957633018494, 0.10561870783567429, 0.5202428102493286, -0.6133663654327393, 0.05639244616031647, 0.5883142948150635, -0.8022153973579407, -0.3203445076942444, 0.48785147070884705, 0.9832749366760254, 0.8061214685440063, 0.32515764236450195, 0.2566949427127838, 0.19950507581233978, 0.5087806582450867, 0.6254203915596008, 0.9676405191421509, -0.8606365919113159, -0.8437559008598328, -0.07196155190467834, 0.07277562469244003, 0.3329673111438751, 0.05710361897945404, 0.4563831388950348, 1.1421953439712524, 0.6870594024658203, 0.3668076694011688, -0.43217703700065613, 0.13300110399723053, -0.2324913889169693, 0.494940847158432, -0.06787186861038208, 0.5441492199897766, -0.8843945264816284, -0.9609987735748291, 1.2155795097351074, -0.9519332051277161, 0.08560467511415482, 0.7817046642303467, 1.3958126306533813, 0.8434995412826538, 0.12114781141281128, -0.5901474356651306, -0.23870457708835602, 1.4420042037963867, 1.1346757411956787, 0.9005347490310669, -1.4982225894927979, 0.19118957221508026, -0.12379325926303864, -0.02369171567261219, 0.1766580194234848, 0.6098675727844238, -0.3412856161594391, -0.7992091774940491, 1.2407371997833252, -0.3564181625843048, 1.3012994527816772, 0.06337694078683853, 0.654879629611969, -1.4022475481033325, -0.8504092693328857, -0.28161466121673584, -0.2925269603729248, -0.6329596638679504, -1.2751996517181396, -0.9551259875297546, -0.22057093679904938, -0.37426865100860596, -0.7573716640472412, -0.6943649053573608, -0.14192144572734833, -0.44985231757164, -0.8016650080680847, -0.3090360760688782, -0.5751528143882751, -1.3365503549575806, 0.5498830676078796, 0.005135305691510439, -2.6745214462280273, 1.1734071969985962, 0.6053091287612915, 0.5459848046302795, -0.8565182685852051, -0.2942928373813629, -0.05998167768120766, -0.3808327913284302, -0.9946015477180481, 0.8483471870422363, 1.1261471509933472, -0.3317386209964752, -1.3496702909469604, 0.8470810651779175, -0.1989007294178009, -0.6910538673400879, 1.1190294027328491, 0.9010276198387146, -0.21124669909477234, 0.4923304319381714, 0.0847095400094986, 1.117836833000183, 0.4127058982849121, -0.08841574192047119, 0.36687612533569336, -0.12114334106445312, 1.3957120180130005, -0.12179029732942581, 0.077385313808918, 0.886789858341217, -0.27085044980049133, -0.0038336506113409996, 0.008444556966423988, -0.49856138229370117, -1.0081849098205566, 0.4198901653289795, 1.125270128250122, 0.7793357968330383, -0.6021351218223572, 1.4103140830993652, -0.1735006421804428, -0.37134090065956116, 0.414767324924469, 0.04973310977220535, 0.7957758903503418, 0.5700789093971252, -1.076154351234436, -0.903512716293335, -0.029925618320703506, 1.5683703422546387, 0.5910823941230774, -0.2899027466773987, -0.024116048589348793, -0.6547548770904541, 0.37573355436325073, -0.990614652633667, -0.11969118565320969, 1.3962416648864746, 0.41995713114738464, 2.0204458236694336, 0.09898456186056137, -0.4472830891609192, 0.1942431926727295, 0.4858044683933258, 0.5545130372047424, 0.22624818980693817, 0.18015781044960022, -1.1931501626968384, 0.22660955786705017, 0.2562824487686157, -0.8474198579788208, 1.0241752862930298, -0.8091786503791809, 0.286825031042099, 1.228274941444397, -0.45614078640937805, 0.6419186592102051, 0.15473105013370514, -1.0709229707717896, -0.2040991485118866, -0.5424923300743103, -0.340275377035141, -0.07024861872196198, 1.5655416250228882, 0.48567450046539307, -0.2214684784412384, 0.40176835656166077, -1.566372036933899, -0.8608502149581909, 0.015459926798939705, -0.562437891960144, 0.033391907811164856, -0.973653256893158, 0.322912335395813, 0.7214628458023071, 0.6933097839355469, -0.02028859220445156, -0.1376802772283554, 0.6455473899841309, 0.8309798836708069, -1.075058102607727, -1.0011613368988037, 1.0633430480957031, 1.3861254453659058, -0.5472493767738342, 2.211514472961426, 1.8693716526031494, -0.43798401951789856, -0.32251065969467163, 0.6862433552742004, 0.10727579146623611, -0.046168480068445206, -0.4658709466457367, -0.2676267623901367, 0.2928955554962158, -0.7507261633872986, 0.6191819310188293, 0.06640982627868652, -0.753211259841919, 0.8936926126480103, -0.8135209083557129, 0.19764451682567596, -0.810695469379425, -1.040635347366333, 1.234630823135376, -0.4901767671108246, -0.29096800088882446, 0.61092609167099, -0.792315661907196, -0.5762624740600586, 0.461006760597229, 0.7816343307495117, -0.018020126968622208, 0.17437301576137543, 0.24199578166007996, 0.5003474950790405, -1.0372700691223145, -1.330670952796936, -0.5658044219017029, 0.4452800154685974, 0.14756378531455994, 0.2450084090232849, 1.0300794839859009, -0.30412259697914124, 0.870910108089447, 0.38235172629356384, 0.15829546749591827, 0.26002970337867737, 1.6106162071228027, -0.1375202089548111, -0.0632244125008583, -0.030508041381835938, 0.023150764405727386, 1.1054117679595947, -0.7235856056213379, -0.18753977119922638, -1.5561391115188599, -0.8024230599403381, -0.678104817867279, -0.3984513282775879, -0.6852229833602905, -0.09905018657445908, -1.192977786064148, -0.21887226402759552, -0.464642196893692, -0.09826398640871048, 1.1751935482025146, 0.21981827914714813, 0.08138485997915268, -0.22045323252677917, 0.3246990144252777, -0.7425065636634827, 0.5136057138442993, -0.24963726103305817, 0.5391274094581604, -0.39768514037132263, -1.2881866693496704, -0.40389740467071533, -0.1617695689201355, -1.2130210399627686, 0.7926399111747742, -0.5056694746017456, 0.5508731603622437, -0.8579067587852478, -1.250243067741394, -0.17232367396354675, -0.005233861971646547, 1.3665556907653809, -0.42359063029289246, -0.1631578654050827, 0.5970317125320435, -0.28148919343948364, -1.6833443641662598, 1.154248833656311, 0.48024067282676697, 0.0919620543718338, 0.11962348222732544, 0.42219892144203186, -0.46199291944503784, -0.31253042817115784, 0.47328421473503113, -0.15459024906158447, -0.8184583187103271, -0.6387639045715332, -0.3061165511608124, 0.018231110647320747, 0.4632967412471771, 0.7881927490234375, -0.4480563998222351, 0.772040843963623, 0.5064675211906433, 1.2364070415496826, -0.9765393733978271, -0.5318951606750488, -0.32021915912628174, 1.8268258571624756, 0.12027577310800552, -0.3261454105377197, -0.38719627261161804, 0.781331479549408, -0.6287186145782471, 1.7228879928588867, 0.3944718539714813, -2.058436155319214, -0.8839390873908997, 0.4915086328983307, -0.37023234367370605, -0.7117977142333984, -0.014271743595600128, 0.5941023826599121, -1.8495533466339111, -1.0282490253448486, -0.4113462269306183, -0.6456348896026611, 0.6336811780929565, -0.9932865500450134, 1.039017677307129, -0.6710695028305054, -0.7295379638671875, -0.9684969782829285, 1.1066360473632812, 0.39652127027511597, 0.9596274495124817, -1.0773521661758423, 0.3244188725948334, 1.0511713027954102, -0.16475936770439148, -0.5198602676391602, 0.03585768863558769, 0.5782613754272461, -0.20982275903224945, 0.6314182877540588, 0.9374935626983643, 0.5843092203140259, -1.406125545501709, 0.7626023292541504, 1.3388891220092773, 0.6367566585540771, 0.16022729873657227, -0.2027437388896942, -0.9371475577354431, 1.283555507659912, -1.6317439079284668, -1.047493577003479, -0.005867050960659981, -0.005798078142106533, 0.17264127731323242, -0.08914030343294144, -0.21191012859344482, -0.6380147337913513, -0.7515561580657959, 0.7111352682113647, 0.3087298274040222, -1.112802505493164, 1.101485013961792, 1.323348045349121, 1.3739237785339355, -0.2687632441520691, 0.4550101161003113, 0.9856563210487366, 0.761765718460083, 0.3328218162059784, 0.9872029423713684, 0.6151891350746155, 0.13287748396396637, -0.1677282452583313, 0.6928427219390869, 0.4605768322944641, -0.7758299708366394, -0.29640281200408936, -0.30413156747817993, 1.1504085063934326, -0.2387481927871704, -0.3155093789100647, -0.8182852864265442, 0.13186435401439667, -0.20507581532001495, 1.1198959350585938, -0.23181729018688202, -0.9123262763023376, -0.1502976268529892, -0.03377137333154678, -0.48632678389549255, -0.8280133605003357, 0.2373509258031845, -0.23601776361465454, 0.7567048072814941, -0.3102611005306244, 1.4384857416152954, -1.3251571655273438, -0.02751833014190197, 0.48867931962013245, -0.1763816624879837, 0.0530136413872242, 0.9837651252746582, -0.062639020383358, -0.16741760075092316, -0.6936882734298706, 0.4533536434173584, 0.6432059407234192, 0.5731143951416016, -1.3247662782669067, -0.3961731791496277, -0.9184303283691406, -1.0071967840194702, 0.09644654393196106, -0.18290434777736664, -2.1483099460601807, -1.1902525424957275, 0.09417843818664551, 0.3286612033843994, 0.2657302916049957, -0.2738599181175232, 0.3018430173397064, 1.3129634857177734, -0.8142006993293762, -0.8004502058029175, -0.5274486541748047, 0.3225241005420685, 0.33157193660736084, -0.20487630367279053, -0.31432223320007324, -0.7077519297599792, -0.45891377329826355, -1.277532696723938, -0.2685339152812958, 0.15427520871162415, -0.6728181838989258, 0.742786169052124, -0.6205862164497375, -0.07872835546731949, -0.3062472641468048, 0.07464642822742462, 0.49733665585517883, 0.13705864548683167, 0.37171390652656555, 0.07327978312969208, -0.9076951146125793, 0.7543707489967346, -0.09241986274719238, 0.30491411685943604, -0.6053906679153442, 0.08028300851583481, 2.755852460861206, 0.02437957562506199, 0.9589326977729797, 0.1298334151506424, 0.06019939109683037, 0.17839644849300385, -0.4614037275314331, -1.7267181873321533, -0.49685969948768616, -0.9633721113204956]\n"
     ]
    }
   ],
   "source": [
    "embedding_vector = embeddings.embed_query(query)\n",
    "print(f\"Embedding vector for query: {embedding_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d0734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "275e8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "new_docs = new_db.similarity_search(query, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2364344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d5924ef4-5751-4363-965f-8121a447e3e9', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='13abdfc3-3b88-44c9-8013-6948c2ba89c3', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='20a4080e-a44f-4600-8869-48fd8165a93e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='b209e602-76f1-43e6-b0ff-188fcb846b8e', metadata={'source': 'Speech.txt'}, page_content='hung up for monuments;'),\n",
       " Document(id='1cf0d8cf-0c62-4003-91ab-bd64f0db63ec', metadata={'source': 'Speech.txt'}, page_content='Our bruised arms hung up')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84319d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
